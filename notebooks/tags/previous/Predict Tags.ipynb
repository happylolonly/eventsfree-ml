{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv');\n",
    "data.head()\n",
    "\n",
    "f = pd.DataFrame();\n",
    "f.head()\n",
    "\n",
    "f['title'] = data['title']\n",
    "f['tags'] = data['tags']\n",
    "\n",
    "f.head()\n",
    "\n",
    "f.to_json('./json-1.json', orient='records', force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/happylol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "import json\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].apply(strip_tags)\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^а-яА-Я0-9(),!?@\\'\\`\\\"\\_\\n]\", \" \")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    return df\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>никто не может остаться равнодушным к венеции ...</td>\n",
       "      <td>письма из венеции</td>\n",
       "      <td>[ \"выставка\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дарит возможности!!!          в э...</td>\n",
       "      <td>дарит возможности!!!          в ...</td>\n",
       "      <td>[ \"тренировка\", \"фитнес\", \"кроссфит\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>бесплатная открытая тренировка по         !   ...</td>\n",
       "      <td>бесплатная открытая тренировка по         !  ...</td>\n",
       "      <td>[ \"фитнес\", \"тренировка\", \"кроссфит \" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хотите работать в германии, но не владеете ...</td>\n",
       "      <td>хотите работать в германии, но не владеете...</td>\n",
       "      <td>[ \"вебинар\", \"германия\", \"работа\" ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>внимание!!!     открытое занятие по     и     ...</td>\n",
       "      <td>внимание!!!     открытое занятие по     и    ...</td>\n",
       "      <td>[ \"фитнес\", \"тренировка\", \"trx\" ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  никто не может остаться равнодушным к венеции ...   \n",
       "1               дарит возможности!!!          в э...   \n",
       "2  бесплатная открытая тренировка по         !   ...   \n",
       "3     хотите работать в германии, но не владеете ...   \n",
       "4  внимание!!!     открытое занятие по     и     ...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                 письма из венеции    \n",
       "1                дарит возможности!!!          в ...   \n",
       "2   бесплатная открытая тренировка по         !  ...   \n",
       "3      хотите работать в германии, но не владеете...   \n",
       "4   внимание!!!     открытое занятие по     и    ...   \n",
       "\n",
       "                                      tags  \n",
       "0                           [ \"выставка\" ]  \n",
       "1   [ \"тренировка\", \"фитнес\", \"кроссфит\" ]  \n",
       "2  [ \"фитнес\", \"тренировка\", \"кроссфит \" ]  \n",
       "3      [ \"вебинар\", \"германия\", \"работа\" ]  \n",
       "4        [ \"фитнес\", \"тренировка\", \"trx\" ]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data.copy();\n",
    "\n",
    "standardize_text(data2, \"text\")\n",
    "standardize_text(data2, \"title\")\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>никто не может остаться равнодушным к венеции ...</td>\n",
       "      <td>письма из венеции</td>\n",
       "      <td>[выставк]</td>\n",
       "      <td>[никт, может, оста, равнодушн, венец, город, т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дарит возможности!!!          в э...</td>\n",
       "      <td>дарит возможности!!!          в ...</td>\n",
       "      <td>[тренировк, фитнес, кроссф]</td>\n",
       "      <td>[дар, возможн, суббот, декабр, состо, открыт, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>бесплатная открытая тренировка по         !   ...</td>\n",
       "      <td>бесплатная открытая тренировка по         !  ...</td>\n",
       "      <td>[фитнес, тренировк, кроссф]</td>\n",
       "      <td>[бесплатн, открыт, тренировк, приход, проб, до...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хотите работать в германии, но не владеете ...</td>\n",
       "      <td>хотите работать в германии, но не владеете...</td>\n",
       "      <td>[вебинар, герман, работ]</td>\n",
       "      <td>[хот, работа, герман, владеет, достаточн, коли...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>внимание!!!     открытое занятие по     и     ...</td>\n",
       "      <td>внимание!!!     открытое занятие по     и    ...</td>\n",
       "      <td>[фитнес, тренировк]</td>\n",
       "      <td>[вниман, открыт, занят, набор, дневн, групп, с...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  никто не может остаться равнодушным к венеции ...   \n",
       "1               дарит возможности!!!          в э...   \n",
       "2  бесплатная открытая тренировка по         !   ...   \n",
       "3     хотите работать в германии, но не владеете ...   \n",
       "4  внимание!!!     открытое занятие по     и     ...   \n",
       "\n",
       "                                               title  \\\n",
       "0                                 письма из венеции    \n",
       "1                дарит возможности!!!          в ...   \n",
       "2   бесплатная открытая тренировка по         !  ...   \n",
       "3      хотите работать в германии, но не владеете...   \n",
       "4   внимание!!!     открытое занятие по     и    ...   \n",
       "\n",
       "                          tags  \\\n",
       "0                    [выставк]   \n",
       "1  [тренировк, фитнес, кроссф]   \n",
       "2  [фитнес, тренировк, кроссф]   \n",
       "3     [вебинар, герман, работ]   \n",
       "4          [фитнес, тренировк]   \n",
       "\n",
       "                                              tokens  \n",
       "0  [никт, может, оста, равнодушн, венец, город, т...  \n",
       "1  [дар, возможн, суббот, декабр, состо, открыт, ...  \n",
       "2  [бесплатн, открыт, тренировк, приход, проб, до...  \n",
       "3  [хот, работа, герман, владеет, достаточн, коли...  \n",
       "4  [вниман, открыт, занят, набор, дневн, групп, с...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "#     print(len(x.text.split(\" \")))\n",
    "    text = x['text'] + ' ' + x['title'] + ' '.join(x['tags']);\n",
    "    return preprocess(text)\n",
    "\n",
    "def preprocessTags(string):\n",
    "    arr = json.loads(string)\n",
    "    return preprocess(' '.join(arr));\n",
    "\n",
    "data2['tags'] = data2['tags'].apply(preprocessTags);\n",
    "data2['tokens'] = data2.apply(tokenize, axis=1);\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>никто не может остаться равнодушным к венеции ...</td>\n",
       "      <td>письма из венеции</td>\n",
       "      <td>выставк</td>\n",
       "      <td>[никт, может, оста, равнодушн, венец, город, т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>дарит возможности!!!          в э...</td>\n",
       "      <td>дарит возможности!!!          в ...</td>\n",
       "      <td>тренировк</td>\n",
       "      <td>[дар, возможн, суббот, декабр, состо, открыт, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>дарит возможности!!!          в э...</td>\n",
       "      <td>дарит возможности!!!          в ...</td>\n",
       "      <td>фитнес</td>\n",
       "      <td>[дар, возможн, суббот, декабр, состо, открыт, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>дарит возможности!!!          в э...</td>\n",
       "      <td>дарит возможности!!!          в ...</td>\n",
       "      <td>кроссф</td>\n",
       "      <td>[дар, возможн, суббот, декабр, состо, открыт, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>бесплатная открытая тренировка по         !   ...</td>\n",
       "      <td>бесплатная открытая тренировка по         !  ...</td>\n",
       "      <td>фитнес</td>\n",
       "      <td>[бесплатн, открыт, тренировк, приход, проб, до...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  никто не может остаться равнодушным к венеции ...   \n",
       "1               дарит возможности!!!          в э...   \n",
       "2               дарит возможности!!!          в э...   \n",
       "3               дарит возможности!!!          в э...   \n",
       "4  бесплатная открытая тренировка по         !   ...   \n",
       "\n",
       "                                               title       tags  \\\n",
       "0                                 письма из венеции     выставк   \n",
       "1                дарит возможности!!!          в ...  тренировк   \n",
       "2                дарит возможности!!!          в ...     фитнес   \n",
       "3                дарит возможности!!!          в ...     кроссф   \n",
       "4   бесплатная открытая тренировка по         !  ...     фитнес   \n",
       "\n",
       "                                              tokens  \n",
       "0  [никт, может, оста, равнодушн, венец, город, т...  \n",
       "1  [дар, возможн, суббот, декабр, состо, открыт, ...  \n",
       "2  [дар, возможн, суббот, декабр, состо, открыт, ...  \n",
       "3  [дар, возможн, суббот, декабр, состо, открыт, ...  \n",
       "4  [бесплатн, открыт, тренировк, приход, проб, до...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_col = 'tags'\n",
    "data3 = pd.DataFrame({\n",
    "    col:np.repeat(data2[col].values, data2[lst_col].str.len())\n",
    "    for col in data2.columns.difference([lst_col])\n",
    "    }).assign(**{lst_col:np.concatenate(data2[lst_col].values)})[data2.columns.tolist()]\n",
    "\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 2563)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = []\n",
    "for row in data3['tokens']:\n",
    "    corpus.append(\" \".join(row))\n",
    "    \n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X = pd.DataFrame(X.toarray())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data3['tags'])\n",
    "\n",
    "list(le.classes_)\n",
    "\n",
    "Y = le.transform(data3['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#train: (109, 2563) (109,) #test: (28, 2563) (28,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "\n",
    "print('#train:', X_train.shape, y_train.shape, '#test:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happylol/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/happylol/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lf = LogisticRegression(random_state=2018).fit(X_train, y_train)\n",
    "pred = lf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14285714285714285"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                            n_informative=2, n_redundant=0,\n",
    "#                            random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                             random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# print(clf.feature_importances_)\n",
    "\n",
    "rfc_prediction = clf.predict(X_test)\n",
    "accuracy_score(rfc_prediction, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happylol/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/Users/happylol/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07142857142857142"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "sorted(clf.cv_results_.keys())\n",
    "clf_prediction = clf.predict(X_test)\n",
    "accuracy_score(rfc_prediction, y_test)\n",
    "                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>(2, 1)</td>\n",
       "      <td>(3, 1)</td>\n",
       "      <td>(4, 1)</td>\n",
       "      <td>(5, 1)</td>\n",
       "      <td>(6, 6)</td>\n",
       "      <td>(7, 2)</td>\n",
       "      <td>(8, 1)</td>\n",
       "      <td>(9, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(14, 1)</td>\n",
       "      <td>(58, 2)</td>\n",
       "      <td>(106, 2)</td>\n",
       "      <td>(107, 2)</td>\n",
       "      <td>(108, 2)</td>\n",
       "      <td>(109, 2)</td>\n",
       "      <td>(110, 2)</td>\n",
       "      <td>(111, 1)</td>\n",
       "      <td>(112, 1)</td>\n",
       "      <td>(113, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(14, 1)</td>\n",
       "      <td>(58, 2)</td>\n",
       "      <td>(106, 2)</td>\n",
       "      <td>(107, 2)</td>\n",
       "      <td>(108, 2)</td>\n",
       "      <td>(109, 2)</td>\n",
       "      <td>(110, 2)</td>\n",
       "      <td>(111, 1)</td>\n",
       "      <td>(112, 1)</td>\n",
       "      <td>(113, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(14, 1)</td>\n",
       "      <td>(58, 2)</td>\n",
       "      <td>(106, 2)</td>\n",
       "      <td>(107, 2)</td>\n",
       "      <td>(108, 2)</td>\n",
       "      <td>(109, 2)</td>\n",
       "      <td>(110, 2)</td>\n",
       "      <td>(111, 1)</td>\n",
       "      <td>(112, 1)</td>\n",
       "      <td>(113, 1)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(14, 1)</td>\n",
       "      <td>(58, 2)</td>\n",
       "      <td>(106, 2)</td>\n",
       "      <td>(107, 2)</td>\n",
       "      <td>(110, 1)</td>\n",
       "      <td>(111, 1)</td>\n",
       "      <td>(114, 1)</td>\n",
       "      <td>(115, 1)</td>\n",
       "      <td>(116, 1)</td>\n",
       "      <td>(117, 3)</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1         2         3         4         5         6    \\\n",
       "0   (0, 1)   (1, 2)    (2, 1)    (3, 1)    (4, 1)    (5, 1)    (6, 6)   \n",
       "1  (14, 1)  (58, 2)  (106, 2)  (107, 2)  (108, 2)  (109, 2)  (110, 2)   \n",
       "2  (14, 1)  (58, 2)  (106, 2)  (107, 2)  (108, 2)  (109, 2)  (110, 2)   \n",
       "3  (14, 1)  (58, 2)  (106, 2)  (107, 2)  (108, 2)  (109, 2)  (110, 2)   \n",
       "4  (14, 1)  (58, 2)  (106, 2)  (107, 2)  (110, 1)  (111, 1)  (114, 1)   \n",
       "\n",
       "        7         8         9    ...    213   214   215   216   217   218  \\\n",
       "0    (7, 2)    (8, 1)    (9, 1)  ...   None  None  None  None  None  None   \n",
       "1  (111, 1)  (112, 1)  (113, 1)  ...   None  None  None  None  None  None   \n",
       "2  (111, 1)  (112, 1)  (113, 1)  ...   None  None  None  None  None  None   \n",
       "3  (111, 1)  (112, 1)  (113, 1)  ...   None  None  None  None  None  None   \n",
       "4  (115, 1)  (116, 1)  (117, 3)  ...   None  None  None  None  None  None   \n",
       "\n",
       "    219   220   221   222  \n",
       "0  None  None  None  None  \n",
       "1  None  None  None  None  \n",
       "2  None  None  None  None  \n",
       "3  None  None  None  None  \n",
       "4  None  None  None  None  \n",
       "\n",
       "[5 rows x 223 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(data3['tokens'])\n",
    "# dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "dictionary.save_as_text('./dict')\n",
    "\n",
    "\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in data3['tokens']]\n",
    "# bow_corpus_tags = [dictionary.doc2bow(doc) for doc in data2['tags']]\n",
    "print(len(bow_corpus))\n",
    "e = pd.DataFrame(bow_corpus)\n",
    "e.head()\n",
    "# len(bow_corpus)\n",
    "\n",
    "# list(le.inverse_transform(l['tags']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@1: 0.0072992700729927005\n",
      "R@1: 0.0072992700729927005\n",
      "Number of examples: 137\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "data3.head()\n",
    "d4 = data3.copy();\n",
    "\n",
    "d4['tags'] = '_label_' + d4['tags'].astype(str)\n",
    "d4.head()\n",
    "\n",
    "# print(X_test)\n",
    "\n",
    "d4.to_csv(path_or_buf='data.test.txt', columns=['text'])\n",
    "d4.to_csv(r'data2.test.txt', columns=['text'], header=None, index=None, sep=' ', mode='a')\n",
    "classifier = fasttext.supervised('data2.train.txt','model', label_prefix='_label_');\n",
    "# model.predict('data.test.txt')\n",
    "result = classifier.test('data2.test.txt')\n",
    "print( 'P@1:', result.precision)\n",
    "print ('R@1:', result.recall)\n",
    "print ('Number of examples:', result.nexamples)\n",
    "# classifier = fasttext.supervised('data.train.txt', 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
