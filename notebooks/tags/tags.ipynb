{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/happylolonly/eventsfree-ml/master/notebooks/tags/data/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gunzip cc.ru.300.bin.gz\n",
    "# !gunzip cc.ru.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{–≤—ã—Å—Ç–∞–≤–∫–∞}</td>\n",
       "      <td>&lt;p&gt;&amp;#x41D;&amp;#x438;&amp;#x43A;&amp;#x442;&amp;#x43E; &amp;#x43D;...</td>\n",
       "      <td>–ü–∏—Å—å–º–∞ –∏–∑ –í–µ–Ω–µ—Ü–∏–∏</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{—Ñ–∏—Ç–Ω–µ—Å, –ø—Ä–∞–∑–¥–Ω–∏–∫}</td>\n",
       "      <td>üéÑüéÑüéÑ–ê –í—ã —É–∂–µ –æ—â—É—â–∞–µ—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏–∫ –∏ –Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ –Ω–∞—Å...</td>\n",
       "      <td>üéÑüéÑüéÑ–ê –í—ã —É–∂–µ –æ—â—É—â–∞–µ—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏–∫ –∏ –Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ –Ω–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, –∫—Ä–æ—Å—Å—Ñ–∏—Ç}</td>\n",
       "      <td>üî•üî•üî•PoisonBox –¥–∞—Ä–∏—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏!!! üî•üî•üî•    –í —ç—Ç—É...</td>\n",
       "      <td>üî•üî•üî•PoisonBox –¥–∞—Ä–∏—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏!!! üî•üî•üî•    –í —ç—Ç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, –∫—Ä–æ—Å—Å—Ñ–∏—Ç }</td>\n",
       "      <td>–ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –æ—Ç–∫—Ä—ã—Ç–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ø–æ CROSSFIT!   ...</td>\n",
       "      <td>–ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –æ—Ç–∫—Ä—ã—Ç–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ø–æ CROSSFIT!  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{–≤–µ–±–∏–Ω–∞—Ä, —Ä–∞–±–æ—Ç–∞, –≥–µ—Ä–º–∞–Ω–∏—è}</td>\n",
       "      <td>üá©üá™ –•–æ—Ç–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ì–µ—Ä–º–∞–Ω–∏–∏, –Ω–æ –Ω–µ –≤–ª–∞–¥–µ–µ—Ç–µ ...</td>\n",
       "      <td>üá©üá™ –•–æ—Ç–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ì–µ—Ä–º–∞–Ω–∏–∏, –Ω–æ –Ω–µ –≤–ª–∞–¥–µ–µ—Ç–µ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tags  \\\n",
       "0                       {–≤—ã—Å—Ç–∞–≤–∫–∞}   \n",
       "1               {—Ñ–∏—Ç–Ω–µ—Å, –ø—Ä–∞–∑–¥–Ω–∏–∫}   \n",
       "2   {—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, –∫—Ä–æ—Å—Å—Ñ–∏—Ç}   \n",
       "3  {—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, –∫—Ä–æ—Å—Å—Ñ–∏—Ç }   \n",
       "4      {–≤–µ–±–∏–Ω–∞—Ä, —Ä–∞–±–æ—Ç–∞, –≥–µ—Ä–º–∞–Ω–∏—è}   \n",
       "\n",
       "                                                text  \\\n",
       "0  <p>&#x41D;&#x438;&#x43A;&#x442;&#x43E; &#x43D;...   \n",
       "1  üéÑüéÑüéÑ–ê –í—ã —É–∂–µ –æ—â—É—â–∞–µ—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏–∫ –∏ –Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ –Ω–∞—Å...   \n",
       "2  üî•üî•üî•PoisonBox –¥–∞—Ä–∏—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏!!! üî•üî•üî•    –í —ç—Ç—É...   \n",
       "3  –ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –æ—Ç–∫—Ä—ã—Ç–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ø–æ CROSSFIT!   ...   \n",
       "4  üá©üá™ –•–æ—Ç–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ì–µ—Ä–º–∞–Ω–∏–∏, –Ω–æ –Ω–µ –≤–ª–∞–¥–µ–µ—Ç–µ ...   \n",
       "\n",
       "                                               title  \n",
       "0                                 –ü–∏—Å—å–º–∞ –∏–∑ –í–µ–Ω–µ—Ü–∏–∏   \n",
       "1   üéÑüéÑüéÑ–ê –í—ã —É–∂–µ –æ—â—É—â–∞–µ—Ç–µ –ø—Ä–∞–∑–¥–Ω–∏–∫ –∏ –Ω–æ–≤–æ–≥–æ–¥–Ω–µ–µ –Ω–∞...  \n",
       "2   üî•üî•üî•PoisonBox –¥–∞—Ä–∏—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏!!! üî•üî•üî•    –í —ç—Ç...  \n",
       "3   –ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –æ—Ç–∫—Ä—ã—Ç–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ø–æ CROSSFIT!  ...  \n",
       "4   üá©üá™ –•–æ—Ç–∏—Ç–µ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –ì–µ—Ä–º–∞–Ω–∏–∏, –Ω–æ –Ω–µ –≤–ª–∞–¥–µ–µ—Ç–µ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data.csv')\n",
    "df = df.replace(r'\\\\n',' ', regex=True) \n",
    "\n",
    "df['tags'] = df['tags'].map(eval) \n",
    "df['tags'] = df['tags'].map(lambda x: set(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove lines where only 1 uniqie tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total count: 77 \n",
      " >2 tags: 33\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter()\n",
    "for tags in df['tags'].values:\n",
    "    for t in tags:\n",
    "        counter[t] += 1\n",
    "counter\n",
    "\n",
    "arr = []\n",
    "for i in counter:\n",
    "    if counter[i] > 2:\n",
    "        arr.append(i);\n",
    "        \n",
    "print('total count:', len(counter), '\\n >2 tags:', len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_white_list = set(arr)\n",
    "df['tags'] = df['tags'].map(lambda x: set(x).intersection(tags_white_list))\n",
    "df = df[df.tags.map(len) > 0]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/happylol/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "from stop_words import get_stop_words\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer('russian')\n",
    "\n",
    "import json\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def standardize_text(df, text_field):\n",
    "    df[text_field] = df[text_field].apply(strip_tags)\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"[^–∞-—è–ê-–Øa-zA-Z]\", \" \")\n",
    "    df[text_field] = df[text_field].str.replace(r\"\\s+\", \" \")\n",
    "    \n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    \n",
    "    stop_words = get_stop_words('russian')\n",
    "    \n",
    "    def stem (text):\n",
    "        temp = []\n",
    "        for word in text.split(\" \"):\n",
    "            if len(word) > 2 and word not in stop_words:\n",
    "                temp.append(stemmer.stem(word))\n",
    "        return \" \".join(temp)\n",
    "        \n",
    "            \n",
    "    df[text_field] = df[text_field].apply(stem)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{–≤—ã—Å—Ç–∞–≤–∫–∞}</td>\n",
       "      <td>–Ω–∏–∫—Ç –æ—Å—Ç–∞ —Ä–∞–≤–Ω–æ–¥—É—à–Ω –≤–µ–Ω–µ—Ü –≥–æ—Ä–æ–¥ —Ç—ã—Å—è—á –ª–∏—Ü —Å—É—â–µ...</td>\n",
       "      <td>–ø–∏—Å—å–º –≤–µ–Ω–µ—Ü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{—Ñ–∏—Ç–Ω–µ—Å, –ø—Ä–∞–∑–¥–Ω–∏–∫}</td>\n",
       "      <td>–æ—â—É—â–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫ –Ω–æ–≤–æ–≥–æ–¥–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–µ–∫–∞–±—Ä —Ñ–∏—Ç–Ω–µ—Å...</td>\n",
       "      <td>–æ—â—É—â–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫ –Ω–æ–≤–æ–≥–æ–¥–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–µ–∫–∞–±—Ä</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å}</td>\n",
       "      <td>poisonbox –¥–∞—Ä –≤–æ–∑–º–æ–∂–Ω —Å—É–±–±–æ—Ç –¥–µ–∫–∞–±—Ä —Å–æ—Å—Ç–æ –æ—Ç–∫—Ä...</td>\n",
       "      <td>poisonbox –¥–∞—Ä –≤–æ–∑–º–æ–∂–Ω —Å—É–±–±–æ—Ç –¥–µ–∫–∞–±—Ä —Å–æ—Å—Ç–æ –æ—Ç–∫—Ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å}</td>\n",
       "      <td>–±–µ—Å–ø–ª–∞—Ç–Ω –æ—Ç–∫—Ä—ã—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫ crossf –ø—Ä–∏—Ö–æ–¥ –ø—Ä–æ–± –¥...</td>\n",
       "      <td>–±–µ—Å–ø–ª–∞—Ç–Ω –æ—Ç–∫—Ä—ã—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫ crossf –ø—Ä–∏—Ö–æ–¥ –ø—Ä–æ–± –¥...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, trx}</td>\n",
       "      <td>–≤–Ω–∏–º–∞–Ω –æ—Ç–∫—Ä—ã—Ç –∑–∞–Ω—è—Ç trx super –Ω–∞–±–æ—Ä –¥–Ω–µ–≤–Ω –≥—Ä—É–ø...</td>\n",
       "      <td>–≤–Ω–∏–º–∞–Ω –æ—Ç–∫—Ä—ã—Ç –∑–∞–Ω—è—Ç trx super –Ω–∞–±–æ—Ä –¥–Ω–µ–≤–Ω –≥—Ä—É–ø–ø</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        tags  \\\n",
       "0                 {–≤—ã—Å—Ç–∞–≤–∫–∞}   \n",
       "1         {—Ñ–∏—Ç–Ω–µ—Å, –ø—Ä–∞–∑–¥–Ω–∏–∫}   \n",
       "2       {—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å}   \n",
       "3       {—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å}   \n",
       "6  {—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞, —Ñ–∏—Ç–Ω–µ—Å, trx}   \n",
       "\n",
       "                                                text  \\\n",
       "0  –Ω–∏–∫—Ç –æ—Å—Ç–∞ —Ä–∞–≤–Ω–æ–¥—É—à–Ω –≤–µ–Ω–µ—Ü –≥–æ—Ä–æ–¥ —Ç—ã—Å—è—á –ª–∏—Ü —Å—É—â–µ...   \n",
       "1  –æ—â—É—â–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫ –Ω–æ–≤–æ–≥–æ–¥–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–µ–∫–∞–±—Ä —Ñ–∏—Ç–Ω–µ—Å...   \n",
       "2  poisonbox –¥–∞—Ä –≤–æ–∑–º–æ–∂–Ω —Å—É–±–±–æ—Ç –¥–µ–∫–∞–±—Ä —Å–æ—Å—Ç–æ –æ—Ç–∫—Ä...   \n",
       "3  –±–µ—Å–ø–ª–∞—Ç–Ω –æ—Ç–∫—Ä—ã—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫ crossf –ø—Ä–∏—Ö–æ–¥ –ø—Ä–æ–± –¥...   \n",
       "6  –≤–Ω–∏–º–∞–Ω –æ—Ç–∫—Ä—ã—Ç –∑–∞–Ω—è—Ç trx super –Ω–∞–±–æ—Ä –¥–Ω–µ–≤–Ω –≥—Ä—É–ø...   \n",
       "\n",
       "                                               title  \n",
       "0                                        –ø–∏—Å—å–º –≤–µ–Ω–µ—Ü  \n",
       "1            –æ—â—É—â–∞ –ø—Ä–∞–∑–¥–Ω–∏–∫ –Ω–æ–≤–æ–≥–æ–¥–Ω –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–µ–∫–∞–±—Ä  \n",
       "2  poisonbox –¥–∞—Ä –≤–æ–∑–º–æ–∂–Ω —Å—É–±–±–æ—Ç –¥–µ–∫–∞–±—Ä —Å–æ—Å—Ç–æ –æ—Ç–∫—Ä...  \n",
       "3  –±–µ—Å–ø–ª–∞—Ç–Ω –æ—Ç–∫—Ä—ã—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫ crossf –ø—Ä–∏—Ö–æ–¥ –ø—Ä–æ–± –¥...  \n",
       "6    –≤–Ω–∏–º–∞–Ω –æ—Ç–∫—Ä—ã—Ç –∑–∞–Ω—è—Ç trx super –Ω–∞–±–æ—Ä –¥–Ω–µ–≤–Ω –≥—Ä—É–ø–ø  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = standardize_text(df, 'text')\n",
    "df = standardize_text(df, 'title')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311, 5)\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for row in df.to_dict(orient='record'):\n",
    "    for tag in row['tags']:\n",
    "        row_copy = row.copy()\n",
    "        row_copy['tag'] = tag\n",
    "        \n",
    "        rows.append(row_copy)\n",
    "        \n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "df['fulltext'] = df[['text', 'title']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['DJ', 'english', 'it', 'trx', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–≤—ã—Å—Ç–∞–≤–∫–∞', '–≥–∏—Ç–∞—Ä–∞',\n",
      "       '–¥–µ—Ç–∏', '–¥–∂–∞–∑', '–¥–∏–∑–∞–π–Ω', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–∫–∏–Ω–æ', '–∫–æ–Ω–∫—É—Ä—Å',\n",
      "       '–∫–æ–Ω—Ü–µ—Ä—Ç', '–ª–µ–∫—Ü–∏—è', '–º–∞—Ä–∫–µ—Ç', '–º–∏—Ç–∞–ø', '–º—É–∑—ã–∫–∞', '–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥',\n",
      "       '–æ–±—É—á–µ–Ω–∏–µ', '–ø—Ä–∞–∑–¥–Ω–∏–∫', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '—Å–µ–º–∏–Ω–∞—Ä', '—Å—Ç–∞—Ä—Ç–∞–ø',\n",
      "       '—Ç–∞–Ω—Ü—ã', '—Ç–µ–∞—Ç—Ä', '—Ç–µ–Ω–∏—Å', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞', '—Ç—É—Ä–Ω–∏—Ä', '—Ñ–∏–ª—å–º',\n",
      "       '—Ñ–∏—Ç–Ω–µ—Å', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '—è—Ä–º–∞—Ä–∫–∞'], dtype=object), array([ 6,  3,  6,  2, 18,  5,  3, 12,  3,  3,  3,  3,  2,  2,  6,  3, 19,\n",
      "       33,  3,  9, 12,  3,  2,  3,  3,  4,  3, 11,  3,  3, 13,  2, 11]))\n",
      "(array(['DJ', 'english', 'it', 'trx', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–≤—ã—Å—Ç–∞–≤–∫–∞', '–≥–∏—Ç–∞—Ä–∞',\n",
      "       '–¥–µ—Ç–∏', '–¥–∂–∞–∑', '–¥–∏–∑–∞–π–Ω', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–∫–∏–Ω–æ', '–∫–æ–Ω–∫—É—Ä—Å',\n",
      "       '–∫–æ–Ω—Ü–µ—Ä—Ç', '–ª–µ–∫—Ü–∏—è', '–º–∞—Ä–∫–µ—Ç', '–º–∏—Ç–∞–ø', '–º—É–∑—ã–∫–∞', '–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥',\n",
      "       '–æ–±—É—á–µ–Ω–∏–µ', '–ø—Ä–∞–∑–¥–Ω–∏–∫', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '—Å–µ–º–∏–Ω–∞—Ä', '—Å—Ç–∞—Ä—Ç–∞–ø',\n",
      "       '—Ç–∞–Ω—Ü—ã', '—Ç–µ–∞—Ç—Ä', '—Ç–µ–Ω–∏—Å', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞', '—Ç—É—Ä–Ω–∏—Ä', '—Ñ–∏–ª—å–º',\n",
      "       '—Ñ–∏—Ç–Ω–µ—Å', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '—è—Ä–º–∞—Ä–∫–∞'], dtype=object), array([ 2,  2,  3,  1,  8,  2,  2,  5,  2,  1,  1,  1,  1,  1,  2,  1,  8,\n",
      "       15,  1,  4,  5,  1,  1,  2,  1,  2,  1,  5,  1,  1,  5,  1,  5]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.3, stratify=df['tag'].values)\n",
    "\n",
    "print(np.unique(train['tag'].values, return_counts=True))\n",
    "print(np.unique(test['tag'].values, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# pip install -U -q git+https://github.com/facebookresearch/fastText.git\n",
    "\n",
    "import fastText\n",
    "\n",
    "FIELD = 'fulltext'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(df, path):\n",
    "    with open(path, 'w+') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write('__label__{} {}\\n'.format(row['tag'], row[FIELD]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(df, '/tmp/train.data')\n",
    "save(train, '/tmp/train.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fastText.train_supervised('/tmp/train.data',\n",
    "                                  pretrainedVectors='/tmp/ml/fasttext/cc.ru.300.vec',\n",
    "                                  dim=300,\n",
    "                                  thread=15,\n",
    "                                  epoch=50,\n",
    "                                  verbose=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, probs = model.predict(test[FIELD].tolist(), k=5)\n",
    "labels = [ll[0].replace('__label__', '') for ll in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "              DJ       0.00      0.00      0.00         2\n",
      "         english       0.00      0.00      0.00         2\n",
      "              it       0.00      0.00      0.00         3\n",
      "             trx       0.00      0.00      0.00         1\n",
      "       –≤–µ—á–µ—Ä–∏–Ω–∫–∞       0.14      0.12      0.13         8\n",
      "        –≤—ã—Å—Ç–∞–≤–∫–∞       0.50      0.50      0.50         2\n",
      "          –≥–∏—Ç–∞—Ä–∞       0.00      0.00      0.00         2\n",
      "            –¥–µ—Ç–∏       0.00      0.00      0.00         5\n",
      "            –¥–∂–∞–∑       0.50      0.50      0.50         2\n",
      "          –¥–∏–∑–∞–π–Ω       0.00      0.00      0.00         1\n",
      "      –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏       0.00      0.00      0.00         1\n",
      "            –∫–∏–Ω–æ       0.00      0.00      0.00         1\n",
      "         –∫–æ–Ω–∫—É—Ä—Å       0.00      0.00      0.00         1\n",
      "         –∫–æ–Ω—Ü–µ—Ä—Ç       0.00      0.00      0.00         1\n",
      "          –ª–µ–∫—Ü–∏—è       0.00      0.00      0.00         2\n",
      "          –º–∞—Ä–∫–µ—Ç       0.00      0.00      0.00         1\n",
      "           –º–∏—Ç–∞–ø       0.43      0.38      0.40         8\n",
      "          –º—É–∑—ã–∫–∞       0.31      0.27      0.29        15\n",
      "      –Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥       0.00      0.00      0.00         1\n",
      "        –æ–±—É—á–µ–Ω–∏–µ       0.00      0.00      0.00         4\n",
      "        –ø—Ä–∞–∑–¥–Ω–∏–∫       0.22      0.40      0.29         5\n",
      "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ       0.00      0.00      0.00         1\n",
      "         —Å–µ–º–∏–Ω–∞—Ä       0.00      0.00      0.00         1\n",
      "         —Å—Ç–∞—Ä—Ç–∞–ø       0.00      0.00      0.00         2\n",
      "           —Ç–∞–Ω—Ü—ã       1.00      1.00      1.00         1\n",
      "           —Ç–µ–∞—Ç—Ä       0.33      0.50      0.40         2\n",
      "           —Ç–µ–Ω–∏—Å       0.00      0.00      0.00         1\n",
      "      —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞       0.17      0.20      0.18         5\n",
      "          —Ç—É—Ä–Ω–∏—Ä       0.00      0.00      0.00         1\n",
      "           —Ñ–∏–ª—å–º       0.00      0.00      0.00         1\n",
      "          —Ñ–∏—Ç–Ω–µ—Å       0.25      0.20      0.22         5\n",
      "      —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è       0.00      0.00      0.00         1\n",
      "         —è—Ä–º–∞—Ä–∫–∞       0.33      0.40      0.36         5\n",
      "\n",
      "       micro avg       0.19      0.19      0.19        94\n",
      "       macro avg       0.13      0.14      0.13        94\n",
      "    weighted avg       0.19      0.19      0.19        94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/happylol/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['tag'].values, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save(df, '/tmp/train.data')\n",
    "model = fastText.train_supervised('/tmp/train.data',\n",
    "                                  pretrainedVectors='/tmp/ml/fasttext/cc.ru.300.vec',\n",
    "                                  dim=300,\n",
    "                                  thread=15,\n",
    "                                  epoch=50,\n",
    "                                  verbose=8)\n",
    "\n",
    "model.quantize(qnorm=True, cutoff=100000)\n",
    "model.save_model('tags_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, probs = model.predict(test[FIELD].tolist(), k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º—É–∑—ã–∫–∞'} {'–≥–∏—Ç–∞—Ä–∞', '–º—É–∑—ã–∫–∞'}\n",
      "{'–º—É–∑—ã–∫–∞', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–≥–∏—Ç–∞—Ä–∞'} {'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–¥–∂–∞–∑', '–º—É–∑—ã–∫–∞'}\n",
      "{'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º—É–∑—ã–∫–∞', '–∫–æ–Ω–∫—É—Ä—Å'} {'—Å—Ç–∞—Ä—Ç–∞–ø', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–∫–æ–Ω–∫—É—Ä—Å'}\n",
      "{'–º–∏—Ç–∞–ø', 'it', '–¥–∏–∑–∞–π–Ω'} {'–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–º–∏—Ç–∞–ø', 'it'}\n",
      "{'–¥–µ—Ç–∏', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'} {'–¥–µ—Ç–∏', '—Ç–µ–Ω–∏—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫'}\n",
      "{'–¥–µ—Ç–∏', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞'} {'—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞', '—Ñ–∏—Ç–Ω–µ—Å'}\n",
      "{'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'} {'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', 'trx'}\n",
      "{'—è—Ä–º–∞—Ä–∫–∞', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'} {'–æ–±—É—á–µ–Ω–∏–µ', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'}\n",
      "{'—è—Ä–º–∞—Ä–∫–∞'} {'–º–∞—Ä–∫–µ—Ç'}\n",
      "{'—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤—ã—Å—Ç–∞–≤–∫–∞'} {'—è—Ä–º–∞—Ä–∫–∞', '–≤—ã—Å—Ç–∞–≤–∫–∞'}\n",
      "{'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º—É–∑—ã–∫–∞'} {'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '—Ç–∞–Ω—Ü—ã'}\n",
      "{'—Å–µ–º–∏–Ω–∞—Ä', '–æ–±—É—á–µ–Ω–∏–µ'} {'–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'}\n",
      "{'DJ', '–º—É–∑—ã–∫–∞'} {'DJ', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'}\n",
      "{'–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'} {'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'}\n",
      "{'–º–∞—Ä–∫–µ—Ç'} {'—è—Ä–º–∞—Ä–∫–∞'}\n",
      "{'—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤—ã—Å—Ç–∞–≤–∫–∞'} {'—è—Ä–º–∞—Ä–∫–∞', '–≤—ã—Å—Ç–∞–≤–∫–∞'}\n",
      "{'–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '—è—Ä–º–∞—Ä–∫–∞', 'it'} {'—Å—Ç–∞—Ä—Ç–∞–ø', '–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '–º–∏—Ç–∞–ø'}\n",
      "{'–¥–µ—Ç–∏', '—Ç–µ–∞—Ç—Ä'} {'–¥–µ—Ç–∏', '–ø—Ä–∞–∑–¥–Ω–∏–∫'}\n",
      "{'english'} {'–æ–±—É—á–µ–Ω–∏–µ'}\n",
      "{'—Å—Ç–∞—Ä—Ç–∞–ø', '–º–∏—Ç–∞–ø'} {'–º–∏—Ç–∞–ø', 'it'}\n",
      "{'–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '—è—Ä–º–∞—Ä–∫–∞', 'it'} {'—Å—Ç–∞—Ä—Ç–∞–ø', '–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '–º–∏—Ç–∞–ø'}\n",
      "{'–∫–æ–Ω—Ü–µ—Ä—Ç'} {'—è—Ä–º–∞—Ä–∫–∞'}\n",
      "{'—Ç—É—Ä–Ω–∏—Ä', '—Ç–µ–Ω–∏—Å'} {'–º–∞—Ä–∫–µ—Ç', '—Ç—É—Ä–Ω–∏—Ä'}\n",
      "{'—è—Ä–º–∞—Ä–∫–∞', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'} {'–æ–±—É—á–µ–Ω–∏–µ', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'}\n",
      "{'–∫–∏–Ω–æ'} {'—Ñ–∏–ª—å–º'}\n",
      "{'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'} {'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', 'trx'}\n",
      "{'–º—É–∑—ã–∫–∞', '–æ–±—É—á–µ–Ω–∏–µ', '—è—Ä–º–∞—Ä–∫–∞', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞'} {'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '—è—Ä–º–∞—Ä–∫–∞', '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è', '–æ–±—É—á–µ–Ω–∏–µ'}\n",
      "{'—Ñ–∏—Ç–Ω–µ—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫', '–∫–æ–Ω–∫—É—Ä—Å'} {'–¥–µ—Ç–∏', '—Ñ–∏—Ç–Ω–µ—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫'}\n",
      "{'DJ', '–º—É–∑—ã–∫–∞'} {'–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º—É–∑—ã–∫–∞'}\n",
      "{'—Å—Ç–∞—Ä—Ç–∞–ø', '–º–∏—Ç–∞–ø'} {'—Å—Ç–∞—Ä—Ç–∞–ø', '–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥'}\n",
      "{'—Ñ–∏—Ç–Ω–µ—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫', '–∫–æ–Ω–∫—É—Ä—Å'} {'–¥–µ—Ç–∏', '—Ñ–∏—Ç–Ω–µ—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫'}\n",
      "{'–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'} {'english', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'}\n",
      "{'–¥–µ—Ç–∏', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'} {'–¥–µ—Ç–∏', '—Ç–µ–Ω–∏—Å', '–ø—Ä–∞–∑–¥–Ω–∏–∫'}\n",
      "{'–º—É–∑—ã–∫–∞'} {'—è—Ä–º–∞—Ä–∫–∞'}\n",
      "{'—Å—Ç–∞—Ä—Ç–∞–ø', '–º–∏—Ç–∞–ø'} {'–º–∏—Ç–∞–ø', 'it'}\n",
      "{'–Ω–µ—Ç–≤–æ—Ä–∫–∏–Ω–≥', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'} {'—Å–µ–º–∏–Ω–∞—Ä', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–º–∏—Ç–∞–ø'}\n",
      "{'–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'} {'english', '–æ–±—É—á–µ–Ω–∏–µ', '–ª–µ–∫—Ü–∏—è'}\n",
      "{'–¥–µ—Ç–∏', '—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞', '—Ç–µ–Ω–∏—Å'} {'–¥–µ—Ç–∏', 'english', '—Ç–µ–Ω–∏—Å'}\n",
      "{'—è—Ä–º–∞—Ä–∫–∞', '–ª–µ–∫—Ü–∏—è', '–≤—ã—Å—Ç–∞–≤–∫–∞'} {'–æ–±—É—á–µ–Ω–∏–µ', '—è—Ä–º–∞—Ä–∫–∞', '–ª–µ–∫—Ü–∏—è'}\n",
      "{'–ª–µ–∫—Ü–∏—è'} {'–º–∏—Ç–∞–ø'}\n",
      "{'—Å—Ç–∞—Ä—Ç–∞–ø', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º–∏—Ç–∞–ø'} {'—Å—Ç–∞—Ä—Ç–∞–ø', '–≤–µ—á–µ—Ä–∏–Ω–∫–∞', '–º—É–∑—ã–∫–∞'}\n",
      "Accuracy: 0.5638297872340425\n"
     ]
    }
   ],
   "source": [
    "mistakes = 0;\n",
    "for i, item in enumerate(test['tags']):\n",
    "    length = len(item)\n",
    "    \n",
    "    prediction = map(lambda x: x.replace('__label__', ''), labels[i][0:length:])\n",
    "    prediction = set(prediction)\n",
    "    \n",
    "    if (item != prediction):\n",
    "        print(item, prediction)\n",
    "        mistakes += 1\n",
    "        \n",
    "print('Accuracy:', (test.shape[0] - mistakes) / test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
